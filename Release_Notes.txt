XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
obsproc_global release 2.0.0 --> released ??? ?, 2014

files:
 *obsproc_global/fix/prepobs_errtable.cdas
 *obsproc_global/fix/prepobs_errtable.global
 *obsproc_global/fix/prepobs_oiqc.oberrs
 *obsproc_global/fix/prepobs_oiqc.oberrs.cdas
 *obsproc_global/jobs/JCDAS_DUMP
 *obsproc_global/jobs/JCDAS_PREP1
 *obsproc_global/jobs/JCDAS_PREP2
 *obsproc_global/jobs/JGDAS_DUMP
 *obsproc_global/jobs/JGDAS_PREP
 *obsproc_global/jobs/JGDAS_PREP_POST
 *obsproc_global/jobs/JGFS_DUMP
 *obsproc_global/jobs/JGFS_PREP
 *obsproc_global/jobs/JGFS_PREP_POST
 *obsproc_global/parm/prepobs_cqcbufr.cdas.parm
 *obsproc_global/parm/prepobs_cqcbufr.gdas.parm
 *obsproc_global/parm/prepobs_cqcbufr.gfs.parm
 *obsproc_global/parm/prepobs_prepacqc.cdas.parm
 *obsproc_global/parm/prepobs_prepacqc.gdas.parm
 *obsproc_global/parm/prepobs_prepacqc.gfs.parm
 *obsproc_global/parm/prepobs_prepdata.cdas.parm
 *obsproc_global/parm/prepobs_prepdata.gdas.parm
 *obsproc_global/parm/prepobs_prepdata.gfs.parm
 *obsproc_global/parm/prepobs_prepssmi.cdas.parm
 *obsproc_global/parm/prepobs_prepssmi.gdas.parm
 *obsproc_global/parm/prepobs_prepssmi.gfs.parm
 *obsproc_global/parm/prepobs_prevents.cdas.parm
 *obsproc_global/parm/prepobs_profcqc.gdas.parm
 *obsproc_global/parm/prepobs_profcqc.gfs.parm
 *obsproc_global/parm/syndat_syndata.gdas.parm
 *obsproc_global/parm/syndat_syndata.gfs.parm
 *obsproc_global/scripts/exglobal_dump.sh.ecf
 *obsproc_global/scripts/exglobal_makeprepbufr.sh.ecf

( * - changed)


 JOB script changes:
   All JOB scripts:
    - Require that the developer export their own particular temporary
      directory root ($DATAROOT) into the job scripts. If $DATAROOT is not set
      in these scripts, the script will abort.
      NOTE: This does not affect production.
      BENEFIT: This avoids having to hardwire a development-specific default
               temporary directory root in these job scripts. This can now be
               different for different development groups.
   JCDAS_PREP1, JCDAS_PREP2, JGDAS_PREP, JGFS_PREP:
    - Changed all "date" commands to "date -u" since WCOSS should always
      present date in UTC.
    - Obtains obsproc_global and obsproc_prep version numbers via imported
      environment variables $obsproc_global_ver and $obsproc_prep_ver, resp.
      These are defined in the upstream ecflow script.
    - Full environmental equivalence.  Streamlined, allows for more
      generalization (e.g., for checkout runs).
    - Exports new environment variable $HOMEobsproc_prep which points to
      directory path for generic prep subdirectories under version control
      (in production this is normally /nwprod/obsproc_prep.$obsproc_prep_ver).
      Replaces /nw${envir} in order to point to files in exec, fix and ush
      directories moved from horizontal to vertical directory structure.
    - Exports new environment variable $HOMEobsproc_network which points to
      directory path for network-specific prep subdirectories under version
      control (in production this is normally
      /nwprod/obsproc_global.$obsproc_nam_ver).  Replaces /nw${envir} in order
      to to files in scripts, parm and fix directories moved from horizontal to
      vertical directory structure.
   JGDAS_PREP, JGFS_PREP:
    - Export environment variable $errPREPDATA_limit as "4" at all center hour
      (cycle) times. Before, it was set to default of "0" at all center hour
      times in obsproc_prep ush script prepobs_makeprepbufr.sh.
      BENEFIT: PREPOBS_PREPDATA will no longer abort in any center hour (cycle)
               time run when it finds no data in either the input "adpupa" or
               "adpsfc" dump files. A diagnostic will be printed in stdout.
               The modern GSI can run ok if these data are not available for
               some unexpected reason.
   JGDAS_PREP_POST, JGFS_PREP_POST:
 !!!- ?????  -- plus updates for these new job scripts below (where needed)

 Model script changes:
   exglobal_makeprepbufr.sh.ecf:
    - Modified to change path to prepobs_makeprepbufr.sh from $ushscript to
      $ushscript_prep (part of vertical structure transition).
    - No longer attempts to dump OSCAT data.
      BENEFIT: This is a waste of time now that the instrument has died
               (2/20/14).
   exglobal_dump.sh.ecf:
    - Minor syntax changes to reduce unncecssary error msgs.

 Fixed file changes:
   prepobs_errtable.cdas, prepobs_errtable.global, prepobs_oiqc.oberrs,
   prepobs_oiqc.oberrs.cdas:
    - No changes (but added here for first time).

 Parm file changes:
   prepobs_prepdata.cdas.parm, prepobs_prepdata.gdas.parm,
   prepobs_prepdata.gfs.parm:
    - Removed comments related to version number, implementation date, and/or
      history. No longer needed now that these are in subversion.
    - New 12'th surface type (representing Coast Guard data) added to array
      JSURFW (=0). 
      BENEFIT: Coast Guard data that report pressure information will be
      encoded into prepbufr file as report type 180/280. 
    - New switch NPKRPT (12*FALSE) to control processing of surface obs with
      missing pressure information (FALSE here means these will continue to be
      discarded).
   prepobs_cqcbufr.cdas.parm, prepobs_cqcbufr.gdas.parm,
   prepobs_cqcbufr.gfs.parm, prepobs_prepacqc.cdas.parm,
   prepobs_prepacqc.gdas.parm, prepobs_prepacqc.gfs.parm,
   prepobs_prepssmi.cdas.parm, prepobs_prepssmi.gdas.parm,
   prepobs_prepssmi.gfs.parm, prepobs_prevents.cdas.parm,
   prepobs_profcqc.gdas.parm, prepobs_profcqc.gfs.parm,
   syndat_syndata.gdas.parm, syndat_syndata.gfs.parm:
    - Removed comments related to version number, implementation date, and/or
      history. No longer needed now that these are in subversion. Otherwise,
      no changes to contents.


 Output changes:
 ---------------
   Jobs JCDAS_PREP1, JCDAS_PREP2, JGDAS_PREP, JGFS_PREP:
    - Coast Guard surface marine mass and wind data will now be processed as
      part of report types 180/280 when pressure information is available. 
    - Surface reports with incomplete wind information will now be retained
      and encoded into the prepbufr file.


 Compute Resource Information:
 -----------------------------
   Jobs JCDAS_PREP1, JCDAS_PREP2, JGDAS_PREP, JGFS_PREP:
    - the CDAS, GDAS, and GFS "prepbufr" files will now be approximately
      1.02 times (102%) as large and  as before since they will now include
      Coast Guard surface marine data and additional surface reports with 
      incomplete wind information that had previously been discarded.
        CDAS: space used by all prepbufr files increases from ~ 130 MBytes/day
              to ~ 133 MBytes/day
        GDAS: space used by all prepbufr files increases from ~ 200 MBytes/day
              to ~ 204 MBytes/day
        GFS:  space used by all prepbufr files increases from ~ 180 MBytes/day
              to ~ 184 MBytes/day
    - no wallclock run time change: CDAS
    - 58 second increase in wallclock run time: GDAS
    - 54 second increase in wallclock run time: GFS
    - uses code from obsproc_prep.v3.0.0
    - no other changes
!!!JGDAS_PREP_POST, JGFS_PREP_POST:
    - uses code from obsproc_prep_post.v2.0.0
    - uses code from obsproc_shared/bufr_remorest.v1.0.0
    - ????
   Jobs JCDAS_DUMP, JGDAS_DUMP, JGFS_DUMP:
    - uses code from obsproc_dump.v3.1.0 (updated from obsproc_dump.v3.0.0)
    - continues to use code from obsproc_shared/bufr_dumplist.v1.0.0
    - no other changes


 Preimplementation Testing Requirements:
 ---------------------------------------
   - Test production jobs JCDAS_PREP1, JCDAS_PREP2, JGDAS_PREP, JGFS_PREP.
   - This is part of the parallel-production test of the OBSPROC Phase 2
     bundle.


 Dissemination:
 --------------
   - The main user of this output is the CDAS, GDAS and GFS models.
   - No change in dissemination.
   - No change in archival on HPSS.


 Special Instructions:
 ---------------------
   This must be implemented simultaneously with the implementations of
   obsproc_dump_monitor.v1.2.0, obsproc_nam.v2.0.0, obsproc_rap.v2.0.0,
   obsproc_rtma.v2.0.0, obsproc_urma.v2.0.0, obsproc_dump.v3.1.0,
   obsproc_dump_post.v2.0.0, obsproc_prep.v3.0.0, obsproc_prep_post.v2.0.0,
   obsproc_satingest.v2.2.0, obsproc_shared/bufr_remorest.v1.0.0 and
   obsproc_shared/bufr_avgdata.v1.0.0.

   This must also be implemented simultaneously with or immediately after the
   w3emc_v2.2.0 implementation.

!!!Please check out file obsproc_global.ver from  
!!!https://svnemc.ncep.noaa.gov/projects/obsproc/branches/VS/versions/LATEST_GREATEST 
!!!and copy to /nwprod/versions, replacing like-named file.

XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
obsproc_global release 1.1.0 --> released Feb 9, 2014

files:
  obsproc_global/jobs/JCDAS_DUMP
  obsproc_global/jobs/JGDAS_DUMP
  obsproc_global/jobs/JGFS_DUMP
  obsproc_global/parm/prepobs_prepssmi.cdas.parm
  obsproc_global/parm/prepobs_prepssmi.gdas.parm
  obsproc_global/parm/prepobs_prepssmi.gfs.parm
 *obsproc_global/scripts/exglobal_dump.sh.ecf

( * - changed)


 Model script changes:
   exglobal_dump.sh.ecf:
    - Modified to dump GOES IR, water vapor, and visible satellite-derived
      winds using a time window of -1.00 to -0.01 hours relative to cycle time
      for the CDAS, GDAS and GFS rather than -1.50 to +1.50 hours relative to
      cycle time.
      BENEFIT: NESDIS is changing the frequency of their GOES satellite
               derived winds from 3-hourly to 1-hourly. The change to
               exglobal_dump.sh.ecf will allow one complete wind set to
               continue to be dumped and assimilated (not changing the time
               window would triple the number of winds dumped and assimilated,
               all over the same locations). This change will also allow winds
               closer to cycle time to now be assimilated.


 Output changes:
 ---------------
   No changes.
  

 Compute Resource Information:
 -----------------------------
   Jobs JCDAS_DUMP, JGDAS_DUMP, JGFS_DUMP:
    - continues to use code from obsproc_dump.v3.0.0
    - continues to use code from obsproc_shared/bufr_dumplist.v1.0.0
    - no other changes


 Preimplementation Testing Requirements:
 ---------------------------------------
   - Test production jobs JCDAS_DUMP, JGDAS_DUMP, JGFS_DUMP.
   - This is part of the parallel-production test of the hourly GOES satellite
     winds.


 Dissemination:
 --------------
   - The main user of this output is the CDAS, GDAS and GFS models.
   - No change in dissemination.
   - No change in archival on HPSS.


 Special Instructions:
 ---------------------
   This must be implemented at EXACTLY the same time as NESDIS' promotion of
   the hourly GOES satellite winds to their production server, and
   simultaneously with the implementations of obsproc_dump_monitor.v1.1.0,
   obsproc_nam.v1.1.0, obsproc_rap.v1.1.0, obsproc_rtma.v1.2.0,
   obsproc_urma.v1.2.0 and obsproc_satingest.v2.1.0.

   Please copy new file
   /meso/save/Dennis.Keyser/HOME/versions/HOURLY_WINDS/obsproc_global.ver
   to /nwprod/versions, replacing like-named file.

XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
obsproc_global release 1.0.0 --> released Feb 8, 2014

files:
 *obsproc_global/jobs/JCDAS_DUMP
 *obsproc_global/jobs/JGDAS_DUMP
 *obsproc_global/jobs/JGFS_DUMP
 *obsproc_global/parm/prepobs_prepssmi.cdas.parm
 *obsproc_global/parm/prepobs_prepssmi.gdas.parm
 *obsproc_global/parm/prepobs_prepssmi.gfs.parm
 *obsproc_global/scripts/exglobal_dump.sh.ecf

( * - changed)


 JOB script changes:
   JCDAS_DUMP, JGDAS_DUMP, JGFS_DUMP:
    - Changed all "date" commands to "date -u" since WCOSS should always
      present date in UTC.
    - Obtains obsproc_global, obsproc_dump and obsproc_shared/bufr_dumplist
      version numbers via imported environment variables $obsproc_global_ver,
      $obsproc_dump_ver and obsproc_shared_bufr_dumplist_ver, resp.
      These are defined in the upstream ecflow script.
    - Full environmental equivalence.  Streamlined, allows for more
      generalization (e.g., for checkout runs).
    - Exports new environment variable $HOMEobsproc_dump which points to
      directory path for generic dump subdirectories under version control
      (in production this is normally /nwprod/obsproc_dump.$obsproc_dump_ver).
      Replaces /nw${envir} in order to point to files in exec, fix and ush
      directories moved from horizontal to vertical directory structure.
    - Exports new environment variable $HOMEobsproc_network which points to
      directory path for network-specific dump subdirectories under version
      control (in production this is normally
      /nwprod/obsproc_global.$obsproc_global_ver).  Replaces /nw${envir} in
      order to point to files in scripts and parm directory moved from
      horizontal to vertical directory structure.
    - Exports new environment variables $HOMEobsproc_shared_bufr_dumplist and
      $FIXobsproc_shared_bufr_dumplist which point to directory path for
      bufr_dumplist fixed file under version control (in production the latter
      is normally
   /nwprod/obsproc_shared/bufr_dumplist.$obsproc_shared_bufr_dumplist_ver/fix).
      Replaces /nw${envir}/fix from old horizontal directory structure.
   JCDAS_DUMP:
    - Uses "cp -p" rather than "cp when copying files to /com/arkv directory
      in order to preserve group ownership as "rstprod" for restricted files.
   JGDAS_DUMP, JGFS_DUMP:
    - Exports new directory path variables for additional ice and sst files.

 Model script changes:
   exglobal_dump.sh.ecf:
    - $USHobsproc_dump replaces $utilscript as the environment variable
      representing the directory path to the ush script check_tanks.sh.
    - Modified to now dump OSCAT scatterometer data in "oscatw" using a time
      window of -3.00 to +2.99 hours relative to cycle time for the CDAS, GDAS
      and GFS.
      BENEFIT: GFS/GDAS parallel runs are now looking at these data.
               Monitoring (RTDM) System graphics.
      N O T I C E:  By the time this was implemented, OSCAT data were no longer
                    available.  The instrument stopped working on 2/20/14 and
                    was declared as "Dead" on 4/3/14.
    - Modified to skip the dumping of NeXRaD VAD winds from level 2 decoder
      (type 002, subtype 017) as part of the "vadwnd" dump ["vadwnd" will still
      contain only NeXRaD VAD winds from radar coded message (type 002, subtype
      008) for now].
      BENEFIT: The default is to now include NeXRaD VAD winds from the level 2
               decoder in the "vadwnd" dump file (as they will be used in the
               next NAM bundle).  The Global GSI cannot handle these at this
               time.
    - Modified to turn off the check for the existence of "wndsat" data tanks
      and thus any attempt to dump these data..
      BENEFIT: The WindSat scatterometer data ingest feed is currently broken
               as these data are now being produced under a new format that
               NCEP does not recognize.  As we transition to the new feed,
               we do not want to inadvertently dump these data in operations.
    - Modified to pick up additional ice, sst, and snow files.
      BENEFIT: GFS/GDAS parallel runs are now looking at these data.

 Parm file changes:
   prepobs_prepssmi.cdas.parm, prepobs_prepssmi.gdas.parm,
   prepobs_prepssmi.gfs.parm:
    - No changes to contents.


 Output changes:
 ---------------
   Jobs JCDAS_DUMP, JGDAS_DUMP, JGFS_DUMP:
    - Creates new dump files
      /com/$NET/prod/$RUN.$PDY/$model.t${cyc}z.oscatw.tm00.bufr_d ,
      where cyc= 00, 06, 12, 18; NET= cdas and model= cdas for RUN= cdas;
      NET= gfs and model= gdas1 for RUN= gdas; and NET= gfs and model= gfs for
      RUN= gfs. --> NO, OSCAT DIED!!
    - "ascatw" dump files will now contain scatterometer winds from METOP-B (as
      well as from METOP-A from before).
   Job JCDAS_DUMP:
    - Users in the "rstprod" group will now be able to read restricted dump
      files in the /com/arkv directory.
  

 Compute Resource Information:
 -----------------------------
   Jobs JCDAS_DUMP, JGDAS_DUMP, JGFS_DUMP:
    - the "ascatw" dump files will now be approximately twice as large
      since they will now include METOP-B (as well as METOP-A from before)
         CDAS: ascatw increases from ~ 17 MBytes/day to ~ 34 MBytes/day
         GDAS: ascatw increases from ~ 17 MBytes/day to ~ 34 MBytes/day
         GFS:  ascatw increases from ~ 14 MBytes/day to ~ 28 MBytes/day
    - disk space required per day for all new output dump files is:
        cdas: oscatw   ~  88 MBytes --> NO, OSCAT DIED!!
        gdas: oscatw   ~  87 MBytes --> NO, OSCAT DIED!!
        gfs:  oscatw   ~  66 MBytes --> NO, OSCAT DIED!!
        TOTAL:       ~   241 MBytes --> NO, OSCAT DIED!!
    - disk space required per day for all new ice, sst & snow grib files is:
        gfs:  fields   ~ 172 MBytes
        gdas: fields   ~ 172 MBytes
        TOTAL:       ~   344 MBytes
    - 3 second increase in wallclock run time
    - uses code from obsproc_dump.v3.0.0
    - uses code from obsproc_shared/bufr_dumplist.v1.0.0
    - no other changes


 Preimplementation Testing Requirements:
 ---------------------------------------
   - Test production jobs JCDAS_DUMP, JGDAS_DUMP, JGFS_DUMP.
   - All changes in this version (1.0.0) will be tested when the next version
     (1.1.0) is tested as part of the parallel-production test of the hourly
     GOES satellite winds.


 Dissemination:
 --------------
   - The main user of this output is the CDAS, GDAS and GFS models.
   - No change in dissemination.
   - No change in archival on HPSS.


 Special Instructions:
 ---------------------
   This must be implemented simultaneously with the implementations of
   obsproc_dump_monitor.v1.0.0, obsproc_dump.v3.0.0, obsproc_nam.v1.0.0,
   obsproc_rap.v1.0.0, obsproc_rtma.v1.1.0, obsproc_urma.v1.1.0,
   obsproc_satingest.v2.0.0, obsproc_shared/bufr_cword.v1.0.0 and
   obsproc_shared/bufr_dumplist.v1.0.0.

   It should be implemented PRIOR to NESDIS' promotion of their hourly GOES
   satellite winds to their production server,

   Please copy new file
   /meso/save/Dennis.Keyser/HOME/versions/obsproc_global.ver to
   /nwprod/versions.

XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
